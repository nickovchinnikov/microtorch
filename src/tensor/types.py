from dataclasses import dataclass
from pathlib import Path
from typing import (
    Callable,
    ClassVar,
    Generic,
    List,
    Optional,
    Protocol,
    Tuple,
    TypeVar,
    Union,
    runtime_checkable,
)

from src.tensor.device import Device, DType, Scalar, Vector

Self = TypeVar("Self", bound="TensorLike")
Data = Union[Scalar, Vector, list, "TensorLike"]
Index = Union[int, slice, List[int], Tuple[Union[int, slice]], "TensorLike", Vector]
Shape = Tuple[int, ...]
Dims = Union[int, Shape]
Axis = Union[int, Tuple[int, ...]]


T = TypeVar("T", bound="TensorLike")

@dataclass(frozen=True)
class Leaf(Generic[T]):
    r"""A leaf node in the computational graph.

    Attributes:
        value (TensorLike): The tensor value at the leaf.
        grad_fn (Callable[[Vector], Vector]): Function to compute the gradient for this node.
    """

    value: "TensorLike"
    grad_fn: Callable[[Vector], Vector]


DependenciesList = List[Leaf["TensorLike"]]


@dataclass
class TProps:
    r"""Base properties shared by tensor classes.

    Attributes:
        _data (Vector): Raw tensor data.
        requires_grad (bool): Whether the tensor requires gradient tracking.
        dependencies (List[TensorType]): List of dependency nodes for autograd.
        device (Device): The device (CPU, GPU, etc.) where the tensor is located.
        dtype (DType): The data type of the tensor values.
    """

    _data: Vector
    requires_grad: bool
    dependencies: DependenciesList
    device: Device
    dtype: DType

    def props(self) -> Tuple:
        return (
            self._data,
            self.requires_grad,
            self.dependencies,
            self.device,
            self.dtype
        )


@runtime_checkable
class TensorLike(Protocol):
    # --- DTypes aliases ---
    float64: ClassVar[DType]
    float32: ClassVar[DType]
    int64: ClassVar[DType]
    int32: ClassVar[DType]
    int16: ClassVar[DType]
    int8: ClassVar[DType]

    # --- Core Properties ---
    
    @property
    def _data(self) -> Vector: ...

    @_data.setter
    def _data(self, data: Vector): ...

    @property
    def requires_grad(self) -> bool: ...

    @requires_grad.setter
    def requires_grad(self, rg: bool): ...

    @property
    def dependencies(self) -> List[Self]: ...

    @dependencies.setter
    def dependencies(self, deps: List[Self]): ...

    @property
    def device(self) -> Device: ...

    @device.setter
    def device(self, device: Device): ...

    @property
    def dtype(self) -> DType: ...

    @dtype.setter
    def dtype(self, dt: DType): ...

    @property
    def grad(self) -> Optional[Vector]: ...

    @grad.setter
    def grad(self, gr: Vector): ...

    # --- Shape Properties ---
    @property
    def shape(self) -> Shape: ...

    @property
    def size(self) -> int: ...

    @property
    def ndim(self) -> int: ...

    @property
    def data(self) -> Vector: ...

    @data.setter
    def data(self, data: Data): ...

    def props(self) -> Tuple: ...
    
    def item(self) -> Scalar: ...

    def __repr__(self) -> str: ...
    def to(self, device: Union[Device, str], dtype: DType = None) -> Self: ...
    def zero_grad(self): ...
    def release_grad(self) -> None: ...
    def backward(self, grad: Optional[Self]): ...
    def clip_grad(self, clip_value: float = 1.0) -> None: ...
    def clip_grad_norm(
        self, max_norm: float = 1.0, norm_type: float = 2.0, eps: float = 1e-6
    ) -> None: ...
    def save(self, file_path: Union[str, Path]) -> None: ...
    @classmethod
    def load(cls, file_path: Union[str, Path]) -> Self: ...
    def detach(self) -> Self: ...
    def clone(self) -> Self: ...
    def copy(self) -> Self: ...
    @staticmethod
    def randn(
        dims: Axis = (),
        requires_grad = False,
        device: Device = Device.CPU,
    ) -> Self: ...

    # --- Unary / Structure Methods ---
    def view(self: Self, shape: Dims) -> Self: ...
    def transpose(self: Self, axis: Optional[Axis]) -> Self: ...
    def squeeze(self: Self, axis: Optional[Axis]) -> Self: ...
    def unsqueeze(self: Self, dim: int) -> Self: ...
    @property
    def T(self: Self) -> Self: ...

    # --- Indexing ---
    def __getitem__(self: Self, index: Index) -> Self: ...

    # --- Elementwise Logic ---
    @staticmethod
    def where(condition: Self, a: Self, b: Self) -> Self: ...
    @staticmethod
    def maximum(a: Data, b: Data) -> Self: ...
    @staticmethod
    def minimum(a: Data, b: Data) -> Self: ...
    def abs(self: Self) -> Self: ...
    def sign(self: Self) -> Self: ...
    def clip(self: Self, min_value: float = None, max_value: float = None) -> Self: ...
    def masked_fill(self: Self, mask: Self, value: float) -> Self: ...
    def threshold(self: Self, threshold: float, value: float) -> Self: ...

    # --- Comparisons ---
    def __eq__(self: Self, other: Data) -> Self: ...
    def __ne__(self: Self, other: Data) -> Self: ...
    def __lt__(self: Self, other: Data) -> Self: ...
    def __le__(self: Self, other: Data) -> Self: ...
    def __gt__(self: Self, other: Data) -> Self: ...
    def __ge__(self: Self, other: Data) -> Self: ...

    # --- Unary Math Ops ---
    def exp(self: Self) -> Self: ...
    def log(self: Self) -> Self: ...
    def tanh(self: Self) -> Self: ...
    def pow(self: Self, p: Scalar) -> Self: ...
    def __pow__(self: Self, p: Scalar) -> Self: ...

    # --- Reduction Ops ---
    def sum(self: Self, axis: Optional[Axis], keepdims: bool = False) -> Self: ...
    def mean(self: Self, axis: Optional[Axis], keepdims: bool = False) -> Self: ...
    def min(self: Self, axis: Optional[Axis], keepdims: bool = False) -> Self: ...
    def max(self: Self, axis: Optional[Axis], keepdims: bool = False) -> Self: ...
    def logsumexp(self: Self, axis: Optional[Axis], keepdims: bool = False) -> Self: ...

    # --- Binary Ops ---
    def dot(self: Self, other: Data) -> Self: ...
    def __matmul__(self: Self, other: Data) -> Self: ...
    def __rmatmul__(self: Self, other: Data) -> Self: ...
    def __add__(self: Self, other: Data) -> Self: ...
    def __radd__(self: Self, other: Data) -> Self: ...
    def __iadd__(self: Self, other: Data) -> Self: ...
    def __sub__(self: Self, other: Data) -> Self: ...
    def __rsub__(self: Self, other: Data) -> Self: ...
    def __isub__(self: Self, other: Data) -> Self: ...
    def __mul__(self: Self, other: Data) -> Self: ...
    def __rmul__(self: Self, other: Data) -> Self: ...
    def __imul__(self: Self, other: Data) -> Self: ...
    def __truediv__(self: Self, other: Data) -> Self: ...
    def __rtruediv__(self: Self, other: Data) -> Self: ...
    def __itruediv__(self: Self, other: Data) -> Self: ...
    def __neg__(self: Self) -> Self: ...
